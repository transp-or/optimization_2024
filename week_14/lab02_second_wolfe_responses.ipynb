{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d644be4e",
   "metadata": {},
   "source": [
    "# Second Wolfe conditions\n",
    "\n",
    "## Introduction to optimization and operations research.\n",
    "\n",
    "Michel Bierlaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a712a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import fsolve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96cf0d",
   "metadata": {},
   "source": [
    "Consider the unconstrained optimization problem\n",
    "$$\\min_{x \\in \\mathbb{R}^2} f(x)=x_1^2+x_1x_2+2x_2^2,\n",
    "$$\n",
    "and the point $x_0=(1,1)^T$.\n",
    "\n",
    "\n",
    "- Calculate Newton's direction at $x_0$.\n",
    "- Verify that it is a descent direction.\n",
    "- Consider the second Wolfe condition with $\\beta_2=0.7$. What are\n",
    "the values of the step $\\alpha$ that verify the condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1522ebdb",
   "metadata": {},
   "source": [
    "First, implement the function and its derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de985ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f(x: np.array) -> float:\n",
    "    \"\"\"Objective function\"\"\"\n",
    "    # Python starts the numbering at zero\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    result = x_1 * x_1 + x_1 * x_2 + 2 * x_2 * x_2\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_zero = np.array([1.0, 1.0])\n",
    "f_zero = f(x_zero)\n",
    "print(f'f({x_zero}) = {f_zero}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df808e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x: np.array) -> np.array:\n",
    "    \"\"\"Gradient of the objective function\"\"\"\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    g_1 = 2 * x_1 + x_2\n",
    "    g_2 = x_1 + 4 * x_2\n",
    "    return np.array([g_1, g_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e47af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_zero = gradient(x_zero)\n",
    "print(f'Gradient of f({x_zero}) = {g_zero}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(x: np.array) -> np.array:\n",
    "    \"\"\"Second derivative matrix of the objective function\"\"\"\n",
    "    # In this case, the hessian does not depend on x\n",
    "    x_1 = x[0]\n",
    "    x_2 = x[1]\n",
    "    h_1_1 = 2\n",
    "    h_1_2 = 1\n",
    "    h_2_1 = 1\n",
    "    h_2_2 = 4\n",
    "    h = np.array([[h_1_1, h_1_2], [h_2_1, h_2_2]])\n",
    "    return h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_zero = hessian(x_zero)\n",
    "print(f'Hessian of f({x_zero}) =\\n{h_zero}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44817995",
   "metadata": {},
   "source": [
    "Note that there exists Python packages for automatic differentiation,\n",
    "such as ``autograd``or ``jax``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b4e5a",
   "metadata": {},
   "source": [
    "Calculate Newton's direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff35cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "newton_direction = np.linalg.solve(h_zero, -g_zero)\n",
    "print(f\"Newton's direction: {newton_direction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ea77d",
   "metadata": {},
   "source": [
    "Verify that it is a descent direction.\n",
    "We calculate the directional derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_derivative = np.inner(newton_direction, g_zero)\n",
    "print(f'Directional derivative: {directional_derivative}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981dd8c2",
   "metadata": {},
   "source": [
    "It must be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbe924",
   "metadata": {},
   "outputs": [],
   "source": [
    "if directional_derivative < 0:\n",
    "    print('Descent direction')\n",
    "else:\n",
    "    print('Not a descent direction')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7add0",
   "metadata": {},
   "source": [
    "Write the function that associates a step alpha along Newton's direction with the value of\n",
    "the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearch(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: value of the objective function\n",
    "    \"\"\"\n",
    "    new_point = x_zero + alpha * newton_direction\n",
    "    return f(new_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9d792",
   "metadata": {},
   "source": [
    "We plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0, 2.5, 100)\n",
    "objective_values = [linesearch(alpha) for alpha in alpha_values]\n",
    "plt.plot(alpha_values, objective_values)\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.grid(True)\n",
    "plt.ylim(top=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f468d13",
   "metadata": {},
   "source": [
    "Consider the second Wolfe condition with $\\beta_2=0.7$.\n",
    "$$\n",
    "\\nabla f(x_\\alpha)^Td_N \\geq \\beta_2 \\nabla f(x_0)^Td_N.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_2 = 0.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0c54c",
   "metadata": {},
   "source": [
    "Consider this equivalent version of the same condition.\n",
    "$$\n",
    "\\frac{\\nabla f(x_\\alpha)^Td_N}{\\nabla f(x_0)^Td_N} \\leq \\beta_2.\n",
    "$$\n",
    "Note that the inequality has changed because $\\nabla f(x_0)^Td_N < 0$.\n",
    "\n",
    "We defined the function calculating that ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_wolfe(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Second wolfe condition\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: ratio of the second Wolfe condition\n",
    "    \"\"\"\n",
    "    new_point = x_zero + alpha * newton_direction\n",
    "    numerator = np.inner(\n",
    "        gradient(new_point), newton_direction\n",
    "    )\n",
    "    denominator = directional_derivative\n",
    "    return numerator / denominator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44146e08",
   "metadata": {},
   "source": [
    "Plot the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wolfe_values = [second_wolfe(alpha) for alpha in alpha_values]\n",
    "plt.plot(alpha_values, objective_values)\n",
    "plt.plot(alpha_values, wolfe_values)\n",
    "plt.axhline(y=beta_2, color='blue', linestyle='--')\n",
    "plt.text(\n",
    "    alpha_values[-1], beta_2, f'beta_2={beta_2}', color='blue', ha='right', va='bottom'\n",
    ")\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.grid(True)\n",
    "plt.ylim(top=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11566f39",
   "metadata": {},
   "source": [
    "The line should intersect two points:\n",
    "\n",
    "- At $\\alpha=0$, it is equal to 1.\n",
    "- At $\\alpha$ corresponding to the minimum of the function, it is equal to 0. Indeed, the directional\n",
    "derivative is zero for this value of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3783eee",
   "metadata": {},
   "source": [
    "What are the values of the step $\\alpha$ that verify the condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2120e",
   "metadata": {},
   "source": [
    "We need to find the values of alpha such that the difference is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(alpha: float) -> float:\n",
    "    \"\"\"\n",
    "    Difference between the first wolfe condition and the function\n",
    "\n",
    "    :param alpha: step along the direction\n",
    "    :return: Wolfe condition\n",
    "    \"\"\"\n",
    "    return beta_2 - second_wolfe(alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c2b94",
   "metadata": {},
   "source": [
    "Find the root of that function. Use the function `fsolve` from `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = 0.25\n",
    "root = fsolve(difference, guess)[0]\n",
    "print(f'Point where the ratio equals beta_2: {root:.2g}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef462f19",
   "metadata": {},
   "source": [
    "Plot the function with the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2474c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alpha_values, objective_values)\n",
    "plt.plot(alpha_values, wolfe_values)\n",
    "plt.axvline(root, color='red', linestyle='--')\n",
    "plt.axhline(y=beta_2, color='blue', linestyle='--')\n",
    "plt.text(\n",
    "    alpha_values[-1], beta_2, f'beta_2={beta_2}', color='blue', ha='right', va='bottom'\n",
    ")\n",
    "plt.text(\n",
    "    root, 2.5, f'alpha={root:.2g}', color='blue', ha='left', va='bottom', rotation=90\n",
    ")\n",
    "plt.xlabel('Step alpha')\n",
    "plt.ylabel('Objective Function Value')\n",
    "plt.title('Line Search Plot')\n",
    "plt.ylim(top=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76866812",
   "metadata": {},
   "source": [
    "The values of the step $\\alpha$ that verify the condition are\n",
    "$$ \\alpha \\geq 0.3$$."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
