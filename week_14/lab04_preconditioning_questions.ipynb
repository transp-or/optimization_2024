{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee7b29a",
   "metadata": {},
   "source": [
    "# Non linear optimization: preconditioning\n",
    "\n",
    "## Introduction to optimization and operations research\n",
    "\n",
    "Michel Bierlaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64992171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444b429",
   "metadata": {},
   "source": [
    "Consider the function $f:\\mathbb{R}^2 \\to \\mathbb{R}$ defined as\n",
    "$$\n",
    "f(x)= \\frac{1}{2}x_1^2 + \\frac{101}{2} x_2^2 +  x_1 x_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b974ef",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Implement a function in Python that calculates the function and its first and second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_function(x: np.array) -> tuple[float, np.array, np.array]:\n",
    "    \"\"\"Calculates the function and its derivatives\n",
    "\n",
    "    :param x: a vector of dimension 2\n",
    "    :return: a tuple with the value of the function, the gradient and the second derivatives matrix\n",
    "    \"\"\"\n",
    "    f = ????\n",
    "    g = ????\n",
    "    h = ????\n",
    "    return f, g, h\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55a8e0",
   "metadata": {},
   "source": [
    "Test it at the point $(1, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1])\n",
    "function, gradient, hessian = the_function(x)\n",
    "print(f'f(x)={function}')\n",
    "print(f'gradient(x)={gradient}')\n",
    "print(f'hessian(x)=\\n{hessian}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e800a33",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Consider a change of variables\n",
    "$$\n",
    "x' = L_k^T x,\n",
    "$$\n",
    "Consider the function in the new variables\n",
    "$$\n",
    "\\tilde{f}(x') = f(L_k^{-T} x').\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0d393",
   "metadata": {},
   "source": [
    "The gradient of the new function is\n",
    "$$ \\nabla \\tilde{f}(x') = L_k^{-1} \\nabla f(L_k^{-T} x'),$$ that is, the solution of the system:\n",
    "$$L_k \\nabla \\tilde{f}(x') = \\nabla f(L_k^{-T} x').$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9ed5a",
   "metadata": {},
   "source": [
    "The hessian of the new function is\n",
    "$$ \\nabla^2 \\tilde{f}(x') = L_k^{-1} \\nabla^2 f(L_k^{-T} x') L_k^{-T}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89ba15",
   "metadata": {},
   "source": [
    "that is, the solution of the system:\n",
    "$$L_k \\nabla^2 \\tilde{f}(x') =  D^T_k,$$\n",
    "where $D_k$ is the solution of the system\n",
    "$$\\nabla^2 f(L_k^{-T} x') = L_k D_k$$\n",
    "Implement a Python function that calculates this function and its first and second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38638e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preconditioned_function(\n",
    "    x: np.array, l_k: np.array\n",
    ") -> tuple[float, np.array, np.array]:\n",
    "    \"\"\"Calculates the preconditioned function and its gradient.\n",
    "\n",
    "    :param x: a vector of dimension 2.\n",
    "    :param l_k:  matrix defining the change of variables.\n",
    "    :return: a tuple with the value of the function, the gradient and the hessian.\n",
    "    \"\"\"\n",
    "    x_original = ????\n",
    "    f, g, h = ????\n",
    "    the_gradient = ????\n",
    "    d_k = ????\n",
    "    the_hessian = ????\n",
    "    return f, the_gradient, the_hessian\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7364da9",
   "metadata": {},
   "source": [
    "Consider $L_k$ to be the Cholesky factor of the second derivative matrix\n",
    "$$\n",
    "L_k L_k^T=  \\nabla^2 f(x_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_k = ????\n",
    "print(l_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff6254",
   "metadata": {},
   "source": [
    "Check that it is indeed the Cholesky factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l_k @ l_k.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8edfd",
   "metadata": {},
   "source": [
    "It must be the same as the hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hessian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3cd7d",
   "metadata": {},
   "source": [
    "Evaluate the preconditioned function at the point $x'=L_k^T x$, where $x=(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_x = ????\n",
    "print(f'{prec_x=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91078a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_function, prec_gradient, prec_hessian = preconditioned_function(prec_x, l_k)\n",
    "print(f'Preconditioned f(x)={prec_function}')\n",
    "print(f'Preconditioned gradient(x)={prec_gradient}')\n",
    "print(f'Preconditioned hessian(x)=\\n{prec_hessian}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87935b66",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Apply one iteration of the steepest descent\n",
    "algorithm on $\\tilde{f}$ from that point, that is\n",
    "$$\n",
    "x'_{k+1} = x'_k - \\alpha \\nabla \\tilde{f}(x'_k),\n",
    "$$\n",
    "where the step size is\n",
    "$$\n",
    "\\alpha = \\frac{\\nabla \\tilde{f}(x'_k)^T \\nabla \\tilde{f}(x'_k)}{\\nabla\n",
    "\\tilde{f}(x'_k)^T \\nabla^2 \\tilde{f}(x'_k) \\nabla \\tilde{f}(x'_k)}.\n",
    "$$\n",
    "It is the Cauchy point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c52ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = ????\n",
    "\n",
    "\n",
    "print(f'{alpha=:.3g}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prec_x = ????\n",
    "print(f'{new_prec_x=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33e65a",
   "metadata": {},
   "source": [
    "Identify the corresponding point in the original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = ????\n",
    "print(f'{new_x=}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
