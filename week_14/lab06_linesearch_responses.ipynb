{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298eb8a1",
   "metadata": {},
   "source": [
    "# Non linear optimization: linesearch\n",
    "\n",
    "## Introduction to optimization and operations research\n",
    "\n",
    "Michel Bierlaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468abab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfbe2c",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Consider the function  $f:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$\n",
    "defined as\n",
    "$$\n",
    "f(x_1, x_2) = x_1^2 + 2x_2^2,\n",
    "$$\n",
    "Implement a Python function that calculates its value, gradient and second derivative matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fced67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(x: np.array) -> tuple[float, np.array, np.array]:\n",
    "    \"\"\"Function and its derivatives\n",
    "\n",
    "    :param x: array of dimension 2\n",
    "    :return: a tuple with the value of the function, the gradient and the hessian\n",
    "    \"\"\"\n",
    "    f = x[0] * x[0] + 2 * x[1] * x[1]\n",
    "    gradient = np.array([[2 * x[0], 4 * x[1]]])\n",
    "    hessian = np.array([[2, 0], [0, 4]])\n",
    "    return f, gradient, hessian\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0c5f7",
   "metadata": {},
   "source": [
    "Test the function at the point $(9, 1).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9979fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([9, 1])\n",
    "function, gradient, hessian = my_function(x)\n",
    "print(f'f(x)={function}')\n",
    "print(f'gradient(x)={gradient}')\n",
    "print(f'hessian(x)=\\n{hessian}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1976854",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Implement the two Wolfe conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be633937",
   "metadata": {},
   "source": [
    "Wolfe conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19903fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolfe_conditions(\n",
    "    current_point: np.array,\n",
    "    direction: np.array,\n",
    "    alpha: float,\n",
    "    a_function: Callable[[np.array], tuple[float, np.array, np.array]],\n",
    "    beta_1,\n",
    "    beta_2,\n",
    ") -> tuple[bool, bool]:\n",
    "    \"\"\"\n",
    "    First wolfe condition\n",
    "\n",
    "    :param current_point: current iterate\n",
    "    :param direction: direction to follow\n",
    "    :param alpha: step along the direction\n",
    "    :param a_function: function being minimized\n",
    "    :param beta_1: parameter of the first Wolfe condition\n",
    "    :param beta_2: parameter of the second Wolfe condition\n",
    "    :return: two boolean corresponding to the two conditions.\n",
    "    \"\"\"\n",
    "    current_function, current_gradient, _ = a_function(current_point)\n",
    "    directional_derivative = np.dot(\n",
    "        current_gradient, direction\n",
    "    )\n",
    "    if directional_derivative >= 0:\n",
    "        error_msg = (\n",
    "            f'The direction must be a descent direction. The directional derivative is non negative: '\n",
    "            f'{directional_derivative}'\n",
    "        )\n",
    "    new_iterate = current_point + alpha * direction\n",
    "    new_function, new_gradient, _ = a_function(new_iterate)\n",
    "    first_wolfe_verified = (\n",
    "        new_function <= current_function + alpha * beta_1 * directional_derivative\n",
    "    )\n",
    "    second_wolfe_verified = (\n",
    "        np.dot(new_gradient, direction) >= beta_2 * directional_derivative\n",
    "    )\n",
    "    return first_wolfe_verified, second_wolfe_verified\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da903f68",
   "metadata": {},
   "source": [
    "Consider the point $x^0 = (9, 1)$, and the direction\n",
    "$$\n",
    "d = \\left(\\begin{array}{c}-18 \\\\ -4\\end{array}\\right).\n",
    "$$\n",
    "Test the Wolfe conditions with $\\alpha_0=0.05$,\n",
    "$\\beta_1=0.01$ and $\\beta_2=0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_0 = np.array([9, 1])\n",
    "direction = np.array([-18, -4])\n",
    "alpha = 0.05\n",
    "beta_1 = 0.01\n",
    "beta_2 = 0.8\n",
    "wolfe_1, wolfe_2 = wolfe_conditions(\n",
    "    current_point=x_0,\n",
    "    direction=direction,\n",
    "    alpha=alpha,\n",
    "    a_function=my_function,\n",
    "    beta_1=beta_1,\n",
    "    beta_2=beta_2,\n",
    ")\n",
    "print(f'Wolfe 1 verified? {wolfe_1}')\n",
    "print(f'Wolfe 2 verified? {wolfe_2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a68f3c",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Implement the line search algorithm to find a step along a direction.\n",
    "At each iteration, print the current value of $\\alpha$, $\\alpha_\\ell$ and $\\alpha_r$, as well as the\n",
    "condition which is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53024efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearh(\n",
    "    current_point: np.array,\n",
    "    direction: np.array,\n",
    "    a_function: Callable[[np.array], tuple[float, np.array, np.array]],\n",
    "    alpha_0: float,\n",
    "    beta_1: float,\n",
    "    beta_2: float,\n",
    "    expansion_lambda: float,\n",
    ") -> float:\n",
    "    \"\"\"Implementation of the line search algorithm (p. 274)\n",
    "\n",
    "    [Bierlaire (2018)](https://transp-or.epfl.ch/books/optimization/html/OptimizationPrinciplesAlgorithms2018.pdf)\n",
    "\n",
    "    :param current_point: current iterate\n",
    "    :param direction: direction to follow\n",
    "    :param a_function: function being minimized\n",
    "    :param alpha_0: initial value for the step\n",
    "    :param beta_1: parameter of the first Wolfe condition\n",
    "    :param beta_2: parameter of the second Wolfe condition\n",
    "    :param expansion_lambda: expansion factor\n",
    "    :return: step verifying both Wolfe conditions.\n",
    "    \"\"\"\n",
    "    if beta_1 >= beta_2:\n",
    "        error_message = f'The value of {beta_1=} and {beta_2} are incompatible.'\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "    alpha = alpha_0\n",
    "    alpha_left = 0\n",
    "    alpha_right = np.inf\n",
    "\n",
    "    both_conditions_are_verified = False\n",
    "\n",
    "    while not both_conditions_are_verified:\n",
    "        print(f'{alpha=:.3g} {alpha_left=:.3g} {alpha_right=:.3g} ', end='')\n",
    "\n",
    "        first_wolfe, second_wolfe = wolfe_conditions(\n",
    "            current_point,\n",
    "            direction,\n",
    "            alpha,\n",
    "            a_function,\n",
    "            beta_1,\n",
    "            beta_2,\n",
    "        )\n",
    "        if not first_wolfe:\n",
    "            # The step is too long\n",
    "            alpha_right = alpha\n",
    "            alpha = (alpha_left + alpha_right) / 2.0\n",
    "            violated = 'W1'\n",
    "        elif not second_wolfe:\n",
    "            # The step is too short\n",
    "            alpha_left = alpha\n",
    "            if alpha_right == np.inf:\n",
    "                alpha *= expansion_lambda\n",
    "            else:\n",
    "                alpha = (alpha_left + alpha_right) / 2.0\n",
    "            violated = 'W2'\n",
    "        else:\n",
    "            both_conditions_are_verified = True\n",
    "            violated = '--'\n",
    "        print(violated)\n",
    "    return alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989f163",
   "metadata": {},
   "source": [
    "Apply the line search algorithm with $\\alpha_0=0.05$,\n",
    "$\\beta_1=0.01$, $\\beta_2=0.8$ and $\\lambda=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_star = linesearh(\n",
    "    current_point=x_0,\n",
    "    direction=direction,\n",
    "    a_function=my_function,\n",
    "    alpha_0=0.05,\n",
    "    beta_1=beta_1,\n",
    "    beta_2=beta_2,\n",
    "    expansion_lambda=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{alpha_star=:.3g}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
